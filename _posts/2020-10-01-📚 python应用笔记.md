---
layout: post
title: 📚 python应用笔记
img: header_post.jpg
tags:
  - python
  - pyautogui
  - fastapi
  - opencv
  - scrapy
  - beautiful-soup
  - scipy
  - sklearn
  - jieba
  - trio
  - 📚
---

- [自动化 pyautogui](#自动化-pyautogui)
  - [异常处理](#异常处理)
  - [模拟点击](#模拟点击)
  - [模拟输入](#模拟输入)
- [网站 fastapi](#网站-fastapi)
- [图像 opencv](#图像-opencv)
  - [基础变换](#基础变换)
  - [模糊 锐化](#模糊-锐化)
  - [色彩分层](#色彩分层)
  - [傅里叶变换 高通低通](#傅里叶变换-高通低通)
  - [图像序列转换为视频](#图像序列转换为视频)
  - [人脸识别](#人脸识别)
- [收集资料 scrapy](#收集资料-scrapy)
- [收集资料 beautiful-soup](#收集资料-beautiful-soup)
- [科学计算 scipy](#科学计算-scipy)
- [机器学习 sklearn](#机器学习-sklearn)
- [分词 jieba](#分词-jieba)
  - [词性过滤](#词性过滤)
  - [自定义词典](#自定义词典)
- [多线程 trio](#多线程-trio)

---

# 自动化 pyautogui

- 默认
- 异常处理
- 模拟点击
- 模拟输入

```py
import pyautogui

size = pyautogui.size() # 屏幕大小
print(pyautogui.position()) # 鼠标位置
print(pyautogui.onScreen(100, 100)) # 判断点是否在屏幕内
pyautogui.moveTo(size.width / 2, size.height / 2, duration = .5) # 鼠标移动到屏幕中央
```

## 异常处理

```py
try: # 当自动化异常退出
    while True:
except KeyboardInterrupt:
    print('\nExit.')
```

## 模拟点击

```py
import pyautogui
import time

time.sleep(2) # 系统准备时间

# 鼠标移到参考图片中央并点击，模拟点击帮助菜单及子菜单
help_pos = pyautogui.locateOnScreen('btn_help.png')
goto_pos = pyautogui.center(help_pos)
pyautogui.moveTo(goto_pos, duration = 1)
pyautogui.click()
pyautogui.moveRel(None, 650, duration = 1) # 鼠标相对移动
pyautogui.click()
```

## 模拟输入

```py
import pyautogui
import time

time.sleep(2) # 系统准备时间

pyautogui.click(button = 'left') # 打开编辑器，模拟输入

pyautogui.typewrite('I like Python.') # 瞬间输入

pyautogui.typewrite('\nI like Python too.', .25) # 逐字输入

pyautogui.typewrite(['enter', 'g', 'o', 'o', 'd', 'left', 'left', 'left', 'backspace', 'G', 'end', '.'], .25) # 字节输入并修改

pyautogui.PAUSE = .5 # 动作间间隔.5秒

pyautogui.keyDown('alt') # 按下alt键
pyautogui.press('a') # 按下a键，全选
pyautogui.press('c') # 按下c键，复制
pyautogui.keyUp('alt') # 松开alt键

pyautogui.hotkey('alt', 'v') # 组合键，粘贴
```

# 网站 fastapi

```bash
$ pip install fastapi # https://fastapi.tiangolo.com
$ pip install uvicorn # WSGI升级版ASGI，支持异步

$ uvicorn main:app --reload --port 8000
$ curl http://127.0.0.1:8000
$ curl http://127.0.0.1:8000/items/1
# API接口调试(Swagger UI) http://127.0.0.1:8000/docs
```

```py
# main.py

from typing import Optional
from fastapi import FastAPI

app = FastAPI()

@app.get("/")
def read_root():
    return {"Hello": "World"}

@app.get("/items/{item_id}")
def read_item(item_id: int, q: Optional[str] = None):
    return {"item_id": item_id, "q": q}
```

# 图像 opencv

- 默认
- 基础变换
- 模糊 锐化
- 色彩分层
- 傅里叶变换 高通低通
- 图像序列转换为视频
- 人脸识别

```py
import opencv as cv2

img = cv2.imread('test.jpg') # imwrite('test.jpg',img)
cv2.imshow('test',img) # cv2 默认 BGR，plt 默认 RGB
# 同理 plt.imshow(img) # 可翻转 pltimg = img[:, :, ::-1]，灰图 cmap = plt.cm.gray，去坐标 plt.axis('off')
# 等待输入 waitKey(0)，destroyAllWindows()，destroyWindows()

rows, cols, chn = img.shape # 行列通道
b, g, r = cv2.split(img) # 拆分通道，或b = img[:, :, 0]
cv2.merge([b, g, r]) # 合并通道

canvas = np.zeros((rows, cols, chn), dtype = img.dtype) # chn 略为单通道可做 mask，dtype 默认 uint8

cv2.line(canvas, (0, 0), (10, 10), (255, 255, 255), 3) # 粗细 -1 为填充
# circle(img, pcenter, r, col)
# polylines(img, [pts], isClosed, col)
# putText(img, text, p, font, size, col)
cv2.copyMakeBorder(img, 1, 1, 1, 1, cv2.BORDER_CONSTANT, value = (255, 255, 255))

cv2.bitwise_and(img1, img2, mask = mask) # 位运算，掩码为零矩阵，bitwise_or()，bitwise_not()

gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY) # 色彩空间转换
# 可选：COLOR_BGR2RGB、COLOR_GRAY2BGR、CV_BGR2HSV、CV_BGR2XYZ、CV_BGR2HLS

cv2.calcHist([img], [chn], mask, [256], [0,255]) # x 轴等级 256，像素级 0 到 255，accumulate 默认不累计，直方图均衡 cv2.equalizeHist([img])
# 同理 plt.hist(img.ravel(), 256)
```

## 基础变换

```py
cv2.resize(img, (10, 10)) # 缩放，或 resize(img, None, fx=.3, fy=.6)

cv2.flip(img, 0) # 翻转，0 垂直 1 水平 -1 垂直水平

m = np.float32([[1, 0, 0], [0, 1, 100]]) # 平移矩阵，参数 [[1,0,x], [0,1,y]]
m = cv2.getRotationMatrix2D(pcenter, angle, scale) # 旋转矩阵
cv2.warpAffine(img, m, (cols, rows)) # 仿射，应用平移旋转等

pos1 = np.float32([[50, 50], [200, 50], [50, 200]]) # 仿射映射位置
pos2 = np.float32([[10, 100], [200, 50], [100, 250]])
m = cv2.getAffineTransform(pos1, pos2) # 仿射矩阵，warpAffine() 应用
m = cv2.getPerspectiveTransform(pos1, pos2) # 透视矩阵，warpPerspective() 应用
```

## 模糊 锐化

```py
# 加盐
for i in range(5000):
    x = np.random.randint(0, rows)
    y = np.random.randint(0, cols)
    img[x, y, :] = 255

kernel = cv2.ones((5, 5), np.uint8) # 卷积核

cv2.erode(img, kernel, iterations = 9) # 腐蚀去噪：压缩，迭代数默认 1
cv2.dilate(img, kernel) # 膨胀去噪：还原为逆腐蚀

cv2.morphologyEx(img, cv2.MORPH_OPEN, kernel) # 开运算(腐蚀后膨胀)去噪
# 可选：
# MORPH_CLOSE 闭运算(膨胀后腐蚀)去散点
# MORPH_GRADIENT 梯度(膨胀减腐蚀)检边
# MORPH_TOPHAT 顶帽(原图减开)或礼帽取白点均光
# MORPH_BLACKHAT 黑帽(闭减原图)取黑点均光

gaussian = cv2.GaussianBlur(gray, (3, 3), 0) # 高斯滤波加权计算，标准差 0
# 均值滤波 blur(img,(3,3))
# 中值滤波非线性 medianBlur(img,3)

ret, binary = cv2.threshold(gray, 127, 255, cv2.THRESH_BINARY) # 二值返回阈值127和处理后图像
# 可选：
# THRESH_BINARY_INV 反二进制阈值
# THRESH_TRUNC 截断阈值
# THRESH_TOZERO_INV 反阈值 0
# THRESH_TOZERO 阈值 0

# Scharr 检边为增强 Sobel，深度 CV_16S 或 CV_32F，10 为 x 一阶导，01 为 y 一阶导
x = cv2.Scharr(gray, cv2.CV_16S, 1, 0)
y = cv2.Scharr(gray, cv2.CV_16S, 0, 1)
absX = cv2.convertScaleAbs(x) # 转uint8
absY = cv2.convertScaleAbs(y)
scharr = cv2.addWeighted(absX, .5, absY, .5, 0) # 融合

# Canny 检边
canny = cv2.Canny(gaussian, 50, 150)

# Laplacian 检边分四邻域和八邻域，LOG(Laplacian of Gaussian) 为增强 Laplacian，最优滤波器
dst = cv2.Laplacian(binary, cv2.CV_16S, ksize = 3)
Laplacian = cv2.convertScaleAbs(dst)
```

## 色彩分层

```py
# 图 K 聚类即色彩分层，聚成n类即色彩分 n 层
criteria = (cv2.TERM_CRITERIA_EPS + cv2.TERM_CRITERIA_MAX_ITER, 10, 1.0)
compactness, label, center = cv2.kmeans(data, 4, None, criteria, 10, cv2.KMEANS_RANDOM_CENTERS)

dst_gray = label.reshape((img.shape[0], img.shape[1]))
center = np.uint8(center) # 彩图需转换为 uint8
res = center[label.flatten()]

dst_color = cv2.cvtColor(res.reshape((img.shape)), cv2.COLOR_BGR2RGB)
cv2.pyrDown(img) # 向下取样，缩小
cv2.pyrUp(img) # 向上取样，放大

# 局部采样即马赛克
def drawMask(x, y, size = 10):
    m = x / size * size
    n = y / size * size
    for i in range(size):
        for j in range(size):
            im[m + i][n + j] = im[m][n]

# 滤镜色卡
def getBGR(img, table, i, j):
    b, g, r = img[i][j] # 原图色
    x = int(g / 4 + int(b / 32) * 64) # 计算颜色坐标
    y = int(r / 4 + int((b % 32) / 4) * 64)
    return lj_map[x][y] # 返回滤镜色
# 读取滤镜色卡 lj_map = cv2.imread('table.png')
```

## 傅里叶变换 高通低通

```py
import numpy as np

f = np.fft.fft2(a) # 傅变返回频率分布复数数组
# nD 傅变 fftn()
# nD 实数傅变 rfftn()
# 傅变采样频率 fftfreq()

fc = np.fft.fftshift(f) # 分布波形移到数组中心，默认数组起始
# 绝对值振幅图即频谱图 np.log(np.abs(fc))

crow, ccol = int(r / 2), int(c / 2) # 中心
fc[crow - 30:crow + 30, ccol - 30:ccol + 30] = 0 # 高通滤波检边
mask = np.zeros((r, c, 2), np.uint8) # 低通滤波模糊
mask[crow - 30:crow + 30, ccol - 30:ccol + 30] = 1
fc = fc * mask

f = np.fft.ifftshift(fc) # 分布波形移到数组起始
a = np.fft.ifft2(f) # 傅逆变
a = np.abs(a) # 复数转换为实数
# 灰图改形 np.float32(a.reshape((r*c,1)))
# 彩图改形 np.float32(a.reshape((r*c,1)).reshape((-1,3)))
```

## 图像序列转换为视频

```py
img_root = 'z:/test/' # 序列文件夹
fps = 24 # 视频帧率

fourcc = cv2.VideoWriter_fourcc(*'XVID') # *'DVIX' 或 *'X264' 需 ffmepg
vw = cv2.VideoWriter('TestVideo.avi', fourcc, fps, (1920, 980), True) # 是否保存图片尺寸

for i in range(900):
    frame = cv2.imread(img_root + str(i + 1) + '.jpg')
    cv2.imshow('frame', frame)
    vw.write(frame)
    if cv2.waitKey(10) & 0xFF == ord('q'):
        break

vw.release()
cv2.destroyAllWindows()
```

## 人脸识别

```py
import cv2 # pip install opencv-python

cascade_path = './models/haarcascade_frontalface_default.xml' # 脸部模型
# cascade_path = './models/haarcascade_frontalface_alt.xml'
# cascade_path = './models/haarcascade_frontalface_alt2.xml'
# cascade_path = './models/haarcascade_frontalface_alt_tree.xml'
eye_cascade_path = './models/haarcascade_eye.xml' # 眼睛模型
# eye_cascade_path = './models/haarcascade_eye_tree_eyeglasses.xml'

def run(imgPath=''):
    outputPath = './output.jpg'
    image = cv2.imread(imgPath) # 图片文件读取
    image_gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY) # 灰度化
    cascade = cv2.CascadeClassifier(cascade_path) # 分类器取得
    facerect = cascade.detectMultiScale(image_gray, scaleFactor=1.1, minNeighbors=2, minSize=(30, 30)) # 脸型检测

    if len(facerect) > 0: # 找到脸了
        for rect in facerect: # 画出脸的位置
            cv2.rectangle(image, tuple(rect[0:2]),tuple(rect[0:2]+rect[2:4]), (0, 255, 0), thickness=3)

        eye_cascade = cv2.CascadeClassifier(eye_cascade_path) # 眼睛检测
        eyes = eye_cascade.detectMultiScale(image_gray)
        for (ex, ey, ew, eh) in eyes:
            cv2.rectangle(image, (ex, ey), (ex + ew, ey + eh), (0, 255, 0), 2)

        cv2.imwrite(outputPath, image) # 结果保存
        print('找到脸了！')
    else:
        print('对不起，没有脸！')
run(imgPath='./face0.jpg')
```

# 收集资料 scrapy

```bash
$ conda install scrapy # 安装
$ scrapy startproject test # 新建
$ scrapy crawl test # 运行
```

- `test`
  - `items.py` 数据类型
  - `pipelines.py` 连接数据库
  - `setting.py`
  - `spiders/test.py`

```py
# test/items.py
import scrapy

class TestItem(scrapy.Item): # 数据类型
  name = scrapy.Field()
  pass
```

```py
# test/pipelines.py
import pymongo

class TestPipeline(object):

  def __init__(self): # 连接mongodb
    client = pymongo.MongqClient('mongodb://localhost:27017')
    self.db = client['testdb']
    self.col = self.db['test']

  def process_item(self, item, spider):
    self.col.insert_one(dict(item)) # 爬取的内容插入数据库
    # return item
```

```py
# test/setting.py
ITEM_PIPELINES = { 'test.pipelines.TestPipeline': 300 }
ROBOTSTXT_OBEY = False
CONCURRENT_REQUESTS = 1
```

```py
# test/spiders/test.py
import scrapy
from test.items import TestItem;

class Test(scrapy.Spider):
  name = 'test' # 爬虫名
  host = 'https://www.test.com' # 目标网站
  keyword = 'test' # 关键词
  page = 1

  def start_requests(self): # 起始页面
    start_url = 'https://www.test.com/search/{}/{}'.format(self.keyword, self.page)
    yield scrapy.Request(url=start_url, callback=self.parse)

  def parse(self, response): # 解析列表
    linka = response.css('.test ul li') # 爬取列表元素
    for item in linka: # 爬取所有a链接
      name = item.css('a::text').extract_first()
      link = self.host + item.css('a::attr(href)').extract_first()
      yield scrapy.Request(link, callback=self.parsePage)
    if(len(list(linka.extract())) == 15):
      self.page += 1
      nextLink = 'https://www.test.com/search/{}/{}'.format(self.keyword, self.page)
      yield scrapy.Request(nextLink, callback=self.parse)

  def parsePage(self, response): # 解析页面
    name = response.css('div.name').extract_first()
    item = TestItem()
    item['name'] = name
    yield item # 爬取的内容以item形式返回迭代
```

# 收集资料 beautiful-soup

```py
from bs4 import BeautifulSoup # pip install beautifulsoup4
import requests
import time
import random

def run():
    page_url = "http://www7b.biglobe.ne.jp/~browneye/english/TOEIC400-1.htm"
    r = requests.get(page_url)
    r.encoding = r.apparent_encoding
    soup = BeautifulSoup(r.text, features="html.parser")

    td_list = soup.find_all("td")
    td_values = [x.text for x in td_list]
    splited_list = []
    for index in range(0, len(td_values), 4):
        word_row = td_values[index: index + 4]
        if word_row[0] == '\u3000':
            continue
        splited_list.append(word_row)

    with open("toeic_words.txt", "w") as f:
        for value in splited_list:
            f.write("{},{}\n".format(value[1], value[2]))
        print("Yes, done.")

if __name__ == "__main__":
    run()
```

# 科学计算 scipy

- [scipy.cluster](http://docs.scipy.org/doc/scipy/reference/cluster.html#scipy.cluster) 向量计算 / Kmean
- [scipy.constants](http://docs.scipy.org/doc/scipy/reference/constants.html#scipy.constants) 物理和数学常量
- [scipy.fftpack](http://docs.scipy.org/doc/scipy/reference/fftpack.html#scipy.fftpack) 傅里叶变换
- [scipy.integrate](http://docs.scipy.org/doc/scipy/reference/integrate.html#scipy.integrate) 积分程序
- [scipy.interpolate](http://docs.scipy.org/doc/scipy/reference/interpolate.html#scipy.interpolate) 插值
- [scipy.io](http://docs.scipy.org/doc/scipy/reference/io.html#scipy.io) 数据输入和输出
- [scipy.linalg](http://docs.scipy.org/doc/scipy/reference/linalg.html#scipy.linalg) 线性代数程序
- [scipy.ndimage](http://docs.scipy.org/doc/scipy/reference/ndimage.html#scipy.ndimage) n-维图像包
- [scipy.odr](http://docs.scipy.org/doc/scipy/reference/odr.html#scipy.odr) 正交距离回归
- [scipy.optimize](http://docs.scipy.org/doc/scipy/reference/optimize.html#scipy.optimize) 优化
- [scipy.signal](http://docs.scipy.org/doc/scipy/reference/signal.html#scipy.signal) 信号处理
- [scipy.sparse](http://docs.scipy.org/doc/scipy/reference/sparse.html#scipy.sparse) 稀疏矩阵
- [scipy.spatial](http://docs.scipy.org/doc/scipy/reference/spatial.html#scipy.spatial) 空间数据结构和算法
- [scipy.special](http://docs.scipy.org/doc/scipy/reference/special.html#scipy.special) 特殊数学函数
- [scipy.stats](http://docs.scipy.org/doc/scipy/reference/stats.html#scipy.stats) 统计

# 机器学习 sklearn

- 监督：数据 x 已知结果(标签 y)
  - 连续标签为回归，离散标签为分类
  - 训练 `fit(x_train,y_train)`
  - 预测 `y_pred=predict(x_test)`
  - 准确率 `score(x_test,y_test)`
- 无监督：数据 x 未知结果(标签 y)
  - 训练并预测 `fit_predict(x)`
  - 训练并转换 `fit_transform(x)`
- `sklearn.linear_model`
  - `LinearRegression()` 线性回归，即多项式拟合
    - 系数 `coef_`
    - 截距 `intercept_`
  - `LogisticRegression(solver='lbfgs, multi_class='auto')` 逻辑回归，即 Sigmoid 函数拟合，二分类
- `sklearn.naive_bayes` 朴素贝叶斯概率分类
  - 先验概率 `class_prior_`
  - 样本数 `class_count_`
  - 均值 `theta_`
  - 方差 `sigma_`
  - 返回预测概率 `predict_proba(x)`
  - 返回增量训练 `partial_fit(x, y, classes=[], sample_weight=np.array([]))`
  - `GaussianNB()` 高斯朴素贝叶斯
  - `MultinomialNB()` 多项式朴素贝叶斯，以次数为特征
  - `BernoulliNB()` 伯努利朴素贝叶斯，以二进制或布尔为特征
- `sklearn.neighbors.KNeighborsClassifier()` K 近邻距离分类
  - 距离和下标 `kneighbors(x)`
- `sklearn.svm.SVC()` 向量机分类
- `sklearn.tree.DecisionTreeClassifier()` 决策树分类
- `sklearn.cluster.KMeans(n_clusters=3)` K 聚类
- `sklearn.decomposition`
  - `PCA(n_components=2)` 降维
  - `LatentDirichletAllocation(n_topics=3, max_iter=100, random_state=1)` 潜在主题分配，训练词频矩阵
    - 主题词频 `topic_word_`
    - 内容词频矩阵(主题数 x 关键词数) `components_`
    - 困惑度 `perplexity(x)`
- `sklearn.feature_extraction.text` 特征提取文字，训练分词转换为词频矩阵
  - 特征词表 `get_feature_names()`
  - `CountVectorizer()` 计数向量化，统计特征词个数
  - `TfidfVectorizer(strip_accents='unicode', max_features=100, stop_words=[], max_df=.99, min_df=.01)` TF-IDF 向量化，统计特征词概率
  - `TfidfTransformer()` TF-IDE 值，训练计数词频转换为概率词频
- `sklearn.model_selection(estimator=lr, cv=4, random_state=1, train_size=.8)` 模型选择
  - 最佳模型 `best_estimator_`
  - 最佳参数 `best_params_`
  - 最佳评分 `best_score_`
  - 训练记录 `cv_results_`
  - 训练 `fit(x, y)`
  - `GridSearchCV(param_grid={weights:[]})` 网格搜索
  - `RandomizedSearchCV(param_distributions={weights:[]}, n_iter=3)` 随机搜索
  - `learning_curve()` 学习曲线，检查拟合情况
  - `validation_curve()` 验证曲线，检查模型情况
  - `train_test_split(x, y)` 随机划分，返回 x 训练 x 测试 y 训练 y 测试 4 个数组
  - `StratifiedShuffleSplit(n_splits=3)` 分层洗牌划分
    - 划分下标 `split(x, y)`
- `sklearn.pipeline.Pipeline([('sc',StandardScaler()), ('pca',PCA(n_components=2)), ('clf',LogisticRegression())])` 管线
- `sklearn.preprocessing`
  - `StandardScaler()` 标准化，缩放到标准正态分布
  - `Normalizer()` 归一化，缩放到 01 区间
  - `Binarizer(threshold=2)` 二值化
  - `LabelBinarizer()` 标签二进制编码，文字二进制化
  - `LabelEncoder()` 标签编码，文字数值化
  - `OneHotEncoder(sparse=False)` 独热编码，数值二进制化
  - `Imputer(missing_values='NaN', strategy='mean')` 缺失值
  - `PolynomialFeatures(degree=2)` 多项式计算
- `sklearn.cross_validation.cross_val_score(x, y, lr, cv=4)` 交叉验证
- `sklearn.metrics(y_test, y_pred)`
  - `mean_absolute_error()` 方差，测回归
  - `mean_squared_error()` 标准差，测回归
  - `r2_score()` R 评分，测回归，趋于 1 好趋于 0 差
  - `accuracy_score()` 准确率，测分类
  - `classification_report()` 分类统计，测分类
  - `confusion_matrix()` 混淆矩阵，测分类
  - `adjusted_rand_score()` 调整系数，测聚类，趋于 1 好趋于-1 差
  - `homogeneity_score()` 同质性，测聚类，单样本群集概率，相反完整性单群集概率
  - `v_measure_score()` V 评分，测聚类，同质性与完整性的均值

# 分词 jieba

- 默认
- 词性过滤
- 自定义词典

```py
import jieba

# 一般过滤
def chinese_cut1(text):
    return ' '.join(jieba.cut(text, cut_all = False)) # 精确模式

datacutted = data.apply(chinese_cut1)
```

## 词性过滤

```py
import jieba.posseg

# 词性过滤
def chinese_cut2(text):
    result = jieba.posseg.cut(text)
    return ' '.join(x.word for x in result if x.flag == 'a' or x.flag == 'n' or x.flag == 'v')

datacutted = data.apply(chinese_cut2)
```

## 自定义词典

- 词典：UTF-8 编码，一词一条，空格间隔，每条 3 个特征，word 为词(必须)，freq 为词频，word_type 为词性

```py
jieba.load_userdict('dict.txt') # 自定义词典

# 动态修改词典
jieba.add_word('newword', freq = 10, tag = 'nz') # 添加自定义词
jieba.del_word('word') # 删除自定义词

jieba.suggest_freq(line.strip(), True) for line in open('dict.txt', 'r', encoding = 'utf8') # 批量修改词频
```

# 多线程 trio

```py
import trio
import numpy as np

async def main():
    async with trio.open_nursery() as nursery:
        send_channel, receive_channel = trio.open_memory_channel(0) # 创建通道，传入通道对象
        nursery.start_soon(thread1, send_channel)
        nursery.start_soon(thread2, receive_channel)

async def thread1(send_channel):
    print("线程1，公司老板")
    async with send_channel:
        for i in range(10):
            await trio.sleep(1.) # 休息
            cmd = np.random.randint(10)
            print("老板发出指示：{!r}".format(cmd)) # 给秘书发指示
            await send_channel.send(cmd)

async def thread2(receive_channel):
    print("线程2，秘书")
    async with receive_channel:
        async for value in receive_channel: # 等待老板指示
            print("秘书收到指示：{!r}".format(value))

trio.run(main)
```
