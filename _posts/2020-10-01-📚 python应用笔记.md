---
layout: post
title: ğŸ“š pythonåº”ç”¨ç¬”è®°
img: header_post.jpg
tags:
  - python
  - pyautogui
  - fastapi
  - opencv
  - scrapy
  - beautiful-soup
  - scipy
  - sklearn
  - jieba
  - trio
  - ğŸ“š
---

- [è‡ªåŠ¨åŒ– pyautogui](#è‡ªåŠ¨åŒ–-pyautogui)
  - [å¼‚å¸¸å¤„ç†](#å¼‚å¸¸å¤„ç†)
  - [æ¨¡æ‹Ÿç‚¹å‡»](#æ¨¡æ‹Ÿç‚¹å‡»)
  - [æ¨¡æ‹Ÿè¾“å…¥](#æ¨¡æ‹Ÿè¾“å…¥)
- [ç½‘ç«™ fastapi](#ç½‘ç«™-fastapi)
- [å›¾åƒ opencv](#å›¾åƒ-opencv)
  - [åŸºç¡€å˜æ¢](#åŸºç¡€å˜æ¢)
  - [æ¨¡ç³Š é”åŒ–](#æ¨¡ç³Š-é”åŒ–)
  - [è‰²å½©åˆ†å±‚](#è‰²å½©åˆ†å±‚)
  - [å‚…é‡Œå¶å˜æ¢ é«˜é€šä½é€š](#å‚…é‡Œå¶å˜æ¢-é«˜é€šä½é€š)
  - [å›¾åƒåºåˆ—è½¬æ¢ä¸ºè§†é¢‘](#å›¾åƒåºåˆ—è½¬æ¢ä¸ºè§†é¢‘)
  - [äººè„¸è¯†åˆ«](#äººè„¸è¯†åˆ«)
- [æ”¶é›†èµ„æ–™ scrapy](#æ”¶é›†èµ„æ–™-scrapy)
- [æ”¶é›†èµ„æ–™ beautiful-soup](#æ”¶é›†èµ„æ–™-beautiful-soup)
- [ç§‘å­¦è®¡ç®— scipy](#ç§‘å­¦è®¡ç®—-scipy)
- [æœºå™¨å­¦ä¹  sklearn](#æœºå™¨å­¦ä¹ -sklearn)
- [åˆ†è¯ jieba](#åˆ†è¯-jieba)
  - [è¯æ€§è¿‡æ»¤](#è¯æ€§è¿‡æ»¤)
  - [è‡ªå®šä¹‰è¯å…¸](#è‡ªå®šä¹‰è¯å…¸)
- [å¤šçº¿ç¨‹ trio](#å¤šçº¿ç¨‹-trio)

---

# è‡ªåŠ¨åŒ– pyautogui

- é»˜è®¤
- å¼‚å¸¸å¤„ç†
- æ¨¡æ‹Ÿç‚¹å‡»
- æ¨¡æ‹Ÿè¾“å…¥

```py
import pyautogui

size = pyautogui.size() # å±å¹•å¤§å°
print(pyautogui.position()) # é¼ æ ‡ä½ç½®
print(pyautogui.onScreen(100, 100)) # åˆ¤æ–­ç‚¹æ˜¯å¦åœ¨å±å¹•å†…
pyautogui.moveTo(size.width / 2, size.height / 2, duration = .5) # é¼ æ ‡ç§»åŠ¨åˆ°å±å¹•ä¸­å¤®
```

## å¼‚å¸¸å¤„ç†

```py
try: # å½“è‡ªåŠ¨åŒ–å¼‚å¸¸é€€å‡º
    while True:
except KeyboardInterrupt:
    print('\nExit.')
```

## æ¨¡æ‹Ÿç‚¹å‡»

```py
import pyautogui
import time

time.sleep(2) # ç³»ç»Ÿå‡†å¤‡æ—¶é—´

# é¼ æ ‡ç§»åˆ°å‚è€ƒå›¾ç‰‡ä¸­å¤®å¹¶ç‚¹å‡»ï¼Œæ¨¡æ‹Ÿç‚¹å‡»å¸®åŠ©èœå•åŠå­èœå•
help_pos = pyautogui.locateOnScreen('btn_help.png')
goto_pos = pyautogui.center(help_pos)
pyautogui.moveTo(goto_pos, duration = 1)
pyautogui.click()
pyautogui.moveRel(None, 650, duration = 1) # é¼ æ ‡ç›¸å¯¹ç§»åŠ¨
pyautogui.click()
```

## æ¨¡æ‹Ÿè¾“å…¥

```py
import pyautogui
import time

time.sleep(2) # ç³»ç»Ÿå‡†å¤‡æ—¶é—´

pyautogui.click(button = 'left') # æ‰“å¼€ç¼–è¾‘å™¨ï¼Œæ¨¡æ‹Ÿè¾“å…¥

pyautogui.typewrite('I like Python.') # ç¬é—´è¾“å…¥

pyautogui.typewrite('\nI like Python too.', .25) # é€å­—è¾“å…¥

pyautogui.typewrite(['enter', 'g', 'o', 'o', 'd', 'left', 'left', 'left', 'backspace', 'G', 'end', '.'], .25) # å­—èŠ‚è¾“å…¥å¹¶ä¿®æ”¹

pyautogui.PAUSE = .5 # åŠ¨ä½œé—´é—´éš”.5ç§’

pyautogui.keyDown('alt') # æŒ‰ä¸‹alté”®
pyautogui.press('a') # æŒ‰ä¸‹aé”®ï¼Œå…¨é€‰
pyautogui.press('c') # æŒ‰ä¸‹cé”®ï¼Œå¤åˆ¶
pyautogui.keyUp('alt') # æ¾å¼€alté”®

pyautogui.hotkey('alt', 'v') # ç»„åˆé”®ï¼Œç²˜è´´
```

# ç½‘ç«™ fastapi

```bash
$ pip install fastapi # https://fastapi.tiangolo.com
$ pip install uvicorn # WSGIå‡çº§ç‰ˆASGIï¼Œæ”¯æŒå¼‚æ­¥

$ uvicorn main:app --reload --port 8000
$ curl http://127.0.0.1:8000
$ curl http://127.0.0.1:8000/items/1
# APIæ¥å£è°ƒè¯•(Swagger UI) http://127.0.0.1:8000/docs
```

```py
# main.py

from typing import Optional
from fastapi import FastAPI

app = FastAPI()

@app.get("/")
def read_root():
    return {"Hello": "World"}

@app.get("/items/{item_id}")
def read_item(item_id: int, q: Optional[str] = None):
    return {"item_id": item_id, "q": q}
```

# å›¾åƒ opencv

- é»˜è®¤
- åŸºç¡€å˜æ¢
- æ¨¡ç³Š é”åŒ–
- è‰²å½©åˆ†å±‚
- å‚…é‡Œå¶å˜æ¢ é«˜é€šä½é€š
- å›¾åƒåºåˆ—è½¬æ¢ä¸ºè§†é¢‘
- äººè„¸è¯†åˆ«

```py
import opencv as cv2

img = cv2.imread('test.jpg') # imwrite('test.jpg',img)
cv2.imshow('test',img) # cv2 é»˜è®¤ BGRï¼Œplt é»˜è®¤ RGB
# åŒç† plt.imshow(img) # å¯ç¿»è½¬ pltimg = img[:, :, ::-1]ï¼Œç°å›¾ cmap = plt.cm.grayï¼Œå»åæ ‡ plt.axis('off')
# ç­‰å¾…è¾“å…¥ waitKey(0)ï¼ŒdestroyAllWindows()ï¼ŒdestroyWindows()

rows, cols, chn = img.shape # è¡Œåˆ—é€šé“
b, g, r = cv2.split(img) # æ‹†åˆ†é€šé“ï¼Œæˆ–b = img[:, :, 0]
cv2.merge([b, g, r]) # åˆå¹¶é€šé“

canvas = np.zeros((rows, cols, chn), dtype = img.dtype) # chn ç•¥ä¸ºå•é€šé“å¯åš maskï¼Œdtype é»˜è®¤ uint8

cv2.line(canvas, (0, 0), (10, 10), (255, 255, 255), 3) # ç²—ç»† -1 ä¸ºå¡«å……
# circle(img, pcenter, r, col)
# polylines(img, [pts], isClosed, col)
# putText(img, text, p, font, size, col)
cv2.copyMakeBorder(img, 1, 1, 1, 1, cv2.BORDER_CONSTANT, value = (255, 255, 255))

cv2.bitwise_and(img1, img2, mask = mask) # ä½è¿ç®—ï¼Œæ©ç ä¸ºé›¶çŸ©é˜µï¼Œbitwise_or()ï¼Œbitwise_not()

gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY) # è‰²å½©ç©ºé—´è½¬æ¢
# å¯é€‰ï¼šCOLOR_BGR2RGBã€COLOR_GRAY2BGRã€CV_BGR2HSVã€CV_BGR2XYZã€CV_BGR2HLS

cv2.calcHist([img], [chn], mask, [256], [0,255]) # x è½´ç­‰çº§ 256ï¼Œåƒç´ çº§ 0 åˆ° 255ï¼Œaccumulate é»˜è®¤ä¸ç´¯è®¡ï¼Œç›´æ–¹å›¾å‡è¡¡ cv2.equalizeHist([img])
# åŒç† plt.hist(img.ravel(), 256)
```

## åŸºç¡€å˜æ¢

```py
cv2.resize(img, (10, 10)) # ç¼©æ”¾ï¼Œæˆ– resize(img, None, fx=.3, fy=.6)

cv2.flip(img, 0) # ç¿»è½¬ï¼Œ0 å‚ç›´ 1 æ°´å¹³ -1 å‚ç›´æ°´å¹³

m = np.float32([[1, 0, 0], [0, 1, 100]]) # å¹³ç§»çŸ©é˜µï¼Œå‚æ•° [[1,0,x], [0,1,y]]
m = cv2.getRotationMatrix2D(pcenter, angle, scale) # æ—‹è½¬çŸ©é˜µ
cv2.warpAffine(img, m, (cols, rows)) # ä»¿å°„ï¼Œåº”ç”¨å¹³ç§»æ—‹è½¬ç­‰

pos1 = np.float32([[50, 50], [200, 50], [50, 200]]) # ä»¿å°„æ˜ å°„ä½ç½®
pos2 = np.float32([[10, 100], [200, 50], [100, 250]])
m = cv2.getAffineTransform(pos1, pos2) # ä»¿å°„çŸ©é˜µï¼ŒwarpAffine() åº”ç”¨
m = cv2.getPerspectiveTransform(pos1, pos2) # é€è§†çŸ©é˜µï¼ŒwarpPerspective() åº”ç”¨
```

## æ¨¡ç³Š é”åŒ–

```py
# åŠ ç›
for i in range(5000):
    x = np.random.randint(0, rows)
    y = np.random.randint(0, cols)
    img[x, y, :] = 255

kernel = cv2.ones((5, 5), np.uint8) # å·ç§¯æ ¸

cv2.erode(img, kernel, iterations = 9) # è…èš€å»å™ªï¼šå‹ç¼©ï¼Œè¿­ä»£æ•°é»˜è®¤ 1
cv2.dilate(img, kernel) # è†¨èƒ€å»å™ªï¼šè¿˜åŸä¸ºé€†è…èš€

cv2.morphologyEx(img, cv2.MORPH_OPEN, kernel) # å¼€è¿ç®—(è…èš€åè†¨èƒ€)å»å™ª
# å¯é€‰ï¼š
# MORPH_CLOSE é—­è¿ç®—(è†¨èƒ€åè…èš€)å»æ•£ç‚¹
# MORPH_GRADIENT æ¢¯åº¦(è†¨èƒ€å‡è…èš€)æ£€è¾¹
# MORPH_TOPHAT é¡¶å¸½(åŸå›¾å‡å¼€)æˆ–ç¤¼å¸½å–ç™½ç‚¹å‡å…‰
# MORPH_BLACKHAT é»‘å¸½(é—­å‡åŸå›¾)å–é»‘ç‚¹å‡å…‰

gaussian = cv2.GaussianBlur(gray, (3, 3), 0) # é«˜æ–¯æ»¤æ³¢åŠ æƒè®¡ç®—ï¼Œæ ‡å‡†å·® 0
# å‡å€¼æ»¤æ³¢ blur(img,(3,3))
# ä¸­å€¼æ»¤æ³¢éçº¿æ€§ medianBlur(img,3)

ret, binary = cv2.threshold(gray, 127, 255, cv2.THRESH_BINARY) # äºŒå€¼è¿”å›é˜ˆå€¼127å’Œå¤„ç†åå›¾åƒ
# å¯é€‰ï¼š
# THRESH_BINARY_INV åäºŒè¿›åˆ¶é˜ˆå€¼
# THRESH_TRUNC æˆªæ–­é˜ˆå€¼
# THRESH_TOZERO_INV åé˜ˆå€¼ 0
# THRESH_TOZERO é˜ˆå€¼ 0

# Scharr æ£€è¾¹ä¸ºå¢å¼º Sobelï¼Œæ·±åº¦ CV_16S æˆ– CV_32Fï¼Œ10 ä¸º x ä¸€é˜¶å¯¼ï¼Œ01 ä¸º y ä¸€é˜¶å¯¼
x = cv2.Scharr(gray, cv2.CV_16S, 1, 0)
y = cv2.Scharr(gray, cv2.CV_16S, 0, 1)
absX = cv2.convertScaleAbs(x) # è½¬uint8
absY = cv2.convertScaleAbs(y)
scharr = cv2.addWeighted(absX, .5, absY, .5, 0) # èåˆ

# Canny æ£€è¾¹
canny = cv2.Canny(gaussian, 50, 150)

# Laplacian æ£€è¾¹åˆ†å››é‚»åŸŸå’Œå…«é‚»åŸŸï¼ŒLOG(Laplacian of Gaussian) ä¸ºå¢å¼º Laplacianï¼Œæœ€ä¼˜æ»¤æ³¢å™¨
dst = cv2.Laplacian(binary, cv2.CV_16S, ksize = 3)
Laplacian = cv2.convertScaleAbs(dst)
```

## è‰²å½©åˆ†å±‚

```py
# å›¾ K èšç±»å³è‰²å½©åˆ†å±‚ï¼Œèšæˆnç±»å³è‰²å½©åˆ† n å±‚
criteria = (cv2.TERM_CRITERIA_EPS + cv2.TERM_CRITERIA_MAX_ITER, 10, 1.0)
compactness, label, center = cv2.kmeans(data, 4, None, criteria, 10, cv2.KMEANS_RANDOM_CENTERS)

dst_gray = label.reshape((img.shape[0], img.shape[1]))
center = np.uint8(center) # å½©å›¾éœ€è½¬æ¢ä¸º uint8
res = center[label.flatten()]

dst_color = cv2.cvtColor(res.reshape((img.shape)), cv2.COLOR_BGR2RGB)
cv2.pyrDown(img) # å‘ä¸‹å–æ ·ï¼Œç¼©å°
cv2.pyrUp(img) # å‘ä¸Šå–æ ·ï¼Œæ”¾å¤§

# å±€éƒ¨é‡‡æ ·å³é©¬èµ›å…‹
def drawMask(x, y, size = 10):
    m = x / size * size
    n = y / size * size
    for i in range(size):
        for j in range(size):
            im[m + i][n + j] = im[m][n]

# æ»¤é•œè‰²å¡
def getBGR(img, table, i, j):
    b, g, r = img[i][j] # åŸå›¾è‰²
    x = int(g / 4 + int(b / 32) * 64) # è®¡ç®—é¢œè‰²åæ ‡
    y = int(r / 4 + int((b % 32) / 4) * 64)
    return lj_map[x][y] # è¿”å›æ»¤é•œè‰²
# è¯»å–æ»¤é•œè‰²å¡ lj_map = cv2.imread('table.png')
```

## å‚…é‡Œå¶å˜æ¢ é«˜é€šä½é€š

```py
import numpy as np

f = np.fft.fft2(a) # å‚…å˜è¿”å›é¢‘ç‡åˆ†å¸ƒå¤æ•°æ•°ç»„
# nD å‚…å˜ fftn()
# nD å®æ•°å‚…å˜ rfftn()
# å‚…å˜é‡‡æ ·é¢‘ç‡ fftfreq()

fc = np.fft.fftshift(f) # åˆ†å¸ƒæ³¢å½¢ç§»åˆ°æ•°ç»„ä¸­å¿ƒï¼Œé»˜è®¤æ•°ç»„èµ·å§‹
# ç»å¯¹å€¼æŒ¯å¹…å›¾å³é¢‘è°±å›¾ np.log(np.abs(fc))

crow, ccol = int(r / 2), int(c / 2) # ä¸­å¿ƒ
fc[crow - 30:crow + 30, ccol - 30:ccol + 30] = 0 # é«˜é€šæ»¤æ³¢æ£€è¾¹
mask = np.zeros((r, c, 2), np.uint8) # ä½é€šæ»¤æ³¢æ¨¡ç³Š
mask[crow - 30:crow + 30, ccol - 30:ccol + 30] = 1
fc = fc * mask

f = np.fft.ifftshift(fc) # åˆ†å¸ƒæ³¢å½¢ç§»åˆ°æ•°ç»„èµ·å§‹
a = np.fft.ifft2(f) # å‚…é€†å˜
a = np.abs(a) # å¤æ•°è½¬æ¢ä¸ºå®æ•°
# ç°å›¾æ”¹å½¢ np.float32(a.reshape((r*c,1)))
# å½©å›¾æ”¹å½¢ np.float32(a.reshape((r*c,1)).reshape((-1,3)))
```

## å›¾åƒåºåˆ—è½¬æ¢ä¸ºè§†é¢‘

```py
img_root = 'z:/test/' # åºåˆ—æ–‡ä»¶å¤¹
fps = 24 # è§†é¢‘å¸§ç‡

fourcc = cv2.VideoWriter_fourcc(*'XVID') # *'DVIX' æˆ– *'X264' éœ€ ffmepg
vw = cv2.VideoWriter('TestVideo.avi', fourcc, fps, (1920, 980), True) # æ˜¯å¦ä¿å­˜å›¾ç‰‡å°ºå¯¸

for i in range(900):
    frame = cv2.imread(img_root + str(i + 1) + '.jpg')
    cv2.imshow('frame', frame)
    vw.write(frame)
    if cv2.waitKey(10) & 0xFF == ord('q'):
        break

vw.release()
cv2.destroyAllWindows()
```

## äººè„¸è¯†åˆ«

```py
import cv2 # pip install opencv-python

cascade_path = './models/haarcascade_frontalface_default.xml' # è„¸éƒ¨æ¨¡å‹
# cascade_path = './models/haarcascade_frontalface_alt.xml'
# cascade_path = './models/haarcascade_frontalface_alt2.xml'
# cascade_path = './models/haarcascade_frontalface_alt_tree.xml'
eye_cascade_path = './models/haarcascade_eye.xml' # çœ¼ç›æ¨¡å‹
# eye_cascade_path = './models/haarcascade_eye_tree_eyeglasses.xml'

def run(imgPath=''):
    outputPath = './output.jpg'
    image = cv2.imread(imgPath) # å›¾ç‰‡æ–‡ä»¶è¯»å–
    image_gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY) # ç°åº¦åŒ–
    cascade = cv2.CascadeClassifier(cascade_path) # åˆ†ç±»å™¨å–å¾—
    facerect = cascade.detectMultiScale(image_gray, scaleFactor=1.1, minNeighbors=2, minSize=(30, 30)) # è„¸å‹æ£€æµ‹

    if len(facerect) > 0: # æ‰¾åˆ°è„¸äº†
        for rect in facerect: # ç”»å‡ºè„¸çš„ä½ç½®
            cv2.rectangle(image, tuple(rect[0:2]),tuple(rect[0:2]+rect[2:4]), (0, 255, 0), thickness=3)

        eye_cascade = cv2.CascadeClassifier(eye_cascade_path) # çœ¼ç›æ£€æµ‹
        eyes = eye_cascade.detectMultiScale(image_gray)
        for (ex, ey, ew, eh) in eyes:
            cv2.rectangle(image, (ex, ey), (ex + ew, ey + eh), (0, 255, 0), 2)

        cv2.imwrite(outputPath, image) # ç»“æœä¿å­˜
        print('æ‰¾åˆ°è„¸äº†ï¼')
    else:
        print('å¯¹ä¸èµ·ï¼Œæ²¡æœ‰è„¸ï¼')
run(imgPath='./face0.jpg')
```

# æ”¶é›†èµ„æ–™ scrapy

```bash
$ conda install scrapy # å®‰è£…
$ scrapy startproject test # æ–°å»º
$ scrapy crawl test # è¿è¡Œ
```

- `test`
  - `items.py` æ•°æ®ç±»å‹
  - `pipelines.py` è¿æ¥æ•°æ®åº“
  - `setting.py`
  - `spiders/test.py`

```py
# test/items.py
import scrapy

class TestItem(scrapy.Item): # æ•°æ®ç±»å‹
  name = scrapy.Field()
  pass
```

```py
# test/pipelines.py
import pymongo

class TestPipeline(object):

  def __init__(self): # è¿æ¥mongodb
    client = pymongo.MongqClient('mongodb://localhost:27017')
    self.db = client['testdb']
    self.col = self.db['test']

  def process_item(self, item, spider):
    self.col.insert_one(dict(item)) # çˆ¬å–çš„å†…å®¹æ’å…¥æ•°æ®åº“
    # return item
```

```py
# test/setting.py
ITEM_PIPELINES = { 'test.pipelines.TestPipeline': 300 }
ROBOTSTXT_OBEY = False
CONCURRENT_REQUESTS = 1
```

```py
# test/spiders/test.py
import scrapy
from test.items import TestItem;

class Test(scrapy.Spider):
  name = 'test' # çˆ¬è™«å
  host = 'https://www.test.com' # ç›®æ ‡ç½‘ç«™
  keyword = 'test' # å…³é”®è¯
  page = 1

  def start_requests(self): # èµ·å§‹é¡µé¢
    start_url = 'https://www.test.com/search/{}/{}'.format(self.keyword, self.page)
    yield scrapy.Request(url=start_url, callback=self.parse)

  def parse(self, response): # è§£æåˆ—è¡¨
    linka = response.css('.test ul li') # çˆ¬å–åˆ—è¡¨å…ƒç´ 
    for item in linka: # çˆ¬å–æ‰€æœ‰aé“¾æ¥
      name = item.css('a::text').extract_first()
      link = self.host + item.css('a::attr(href)').extract_first()
      yield scrapy.Request(link, callback=self.parsePage)
    if(len(list(linka.extract())) == 15):
      self.page += 1
      nextLink = 'https://www.test.com/search/{}/{}'.format(self.keyword, self.page)
      yield scrapy.Request(nextLink, callback=self.parse)

  def parsePage(self, response): # è§£æé¡µé¢
    name = response.css('div.name').extract_first()
    item = TestItem()
    item['name'] = name
    yield item # çˆ¬å–çš„å†…å®¹ä»¥itemå½¢å¼è¿”å›è¿­ä»£
```

# æ”¶é›†èµ„æ–™ beautiful-soup

```py
from bs4 import BeautifulSoup # pip install beautifulsoup4
import requests
import time
import random

def run():
    page_url = "http://www7b.biglobe.ne.jp/~browneye/english/TOEIC400-1.htm"
    r = requests.get(page_url)
    r.encoding = r.apparent_encoding
    soup = BeautifulSoup(r.text, features="html.parser")

    td_list = soup.find_all("td")
    td_values = [x.text for x in td_list]
    splited_list = []
    for index in range(0, len(td_values), 4):
        word_row = td_values[index: index + 4]
        if word_row[0] == '\u3000':
            continue
        splited_list.append(word_row)

    with open("toeic_words.txt", "w") as f:
        for value in splited_list:
            f.write("{},{}\n".format(value[1], value[2]))
        print("Yes, done.")

if __name__ == "__main__":
    run()
```

# ç§‘å­¦è®¡ç®— scipy

- [scipy.cluster](http://docs.scipy.org/doc/scipy/reference/cluster.html#scipy.cluster) å‘é‡è®¡ç®— / Kmean
- [scipy.constants](http://docs.scipy.org/doc/scipy/reference/constants.html#scipy.constants) ç‰©ç†å’Œæ•°å­¦å¸¸é‡
- [scipy.fftpack](http://docs.scipy.org/doc/scipy/reference/fftpack.html#scipy.fftpack) å‚…é‡Œå¶å˜æ¢
- [scipy.integrate](http://docs.scipy.org/doc/scipy/reference/integrate.html#scipy.integrate) ç§¯åˆ†ç¨‹åº
- [scipy.interpolate](http://docs.scipy.org/doc/scipy/reference/interpolate.html#scipy.interpolate) æ’å€¼
- [scipy.io](http://docs.scipy.org/doc/scipy/reference/io.html#scipy.io) æ•°æ®è¾“å…¥å’Œè¾“å‡º
- [scipy.linalg](http://docs.scipy.org/doc/scipy/reference/linalg.html#scipy.linalg) çº¿æ€§ä»£æ•°ç¨‹åº
- [scipy.ndimage](http://docs.scipy.org/doc/scipy/reference/ndimage.html#scipy.ndimage) n-ç»´å›¾åƒåŒ…
- [scipy.odr](http://docs.scipy.org/doc/scipy/reference/odr.html#scipy.odr) æ­£äº¤è·ç¦»å›å½’
- [scipy.optimize](http://docs.scipy.org/doc/scipy/reference/optimize.html#scipy.optimize) ä¼˜åŒ–
- [scipy.signal](http://docs.scipy.org/doc/scipy/reference/signal.html#scipy.signal) ä¿¡å·å¤„ç†
- [scipy.sparse](http://docs.scipy.org/doc/scipy/reference/sparse.html#scipy.sparse) ç¨€ç–çŸ©é˜µ
- [scipy.spatial](http://docs.scipy.org/doc/scipy/reference/spatial.html#scipy.spatial) ç©ºé—´æ•°æ®ç»“æ„å’Œç®—æ³•
- [scipy.special](http://docs.scipy.org/doc/scipy/reference/special.html#scipy.special) ç‰¹æ®Šæ•°å­¦å‡½æ•°
- [scipy.stats](http://docs.scipy.org/doc/scipy/reference/stats.html#scipy.stats) ç»Ÿè®¡

# æœºå™¨å­¦ä¹  sklearn

- ç›‘ç£ï¼šæ•°æ® x å·²çŸ¥ç»“æœ(æ ‡ç­¾ y)
  - è¿ç»­æ ‡ç­¾ä¸ºå›å½’ï¼Œç¦»æ•£æ ‡ç­¾ä¸ºåˆ†ç±»
  - è®­ç»ƒ `fit(x_train,y_train)`
  - é¢„æµ‹ `y_pred=predict(x_test)`
  - å‡†ç¡®ç‡ `score(x_test,y_test)`
- æ— ç›‘ç£ï¼šæ•°æ® x æœªçŸ¥ç»“æœ(æ ‡ç­¾ y)
  - è®­ç»ƒå¹¶é¢„æµ‹ `fit_predict(x)`
  - è®­ç»ƒå¹¶è½¬æ¢ `fit_transform(x)`
- `sklearn.linear_model`
  - `LinearRegression()` çº¿æ€§å›å½’ï¼Œå³å¤šé¡¹å¼æ‹Ÿåˆ
    - ç³»æ•° `coef_`
    - æˆªè· `intercept_`
  - `LogisticRegression(solver='lbfgs, multi_class='auto')` é€»è¾‘å›å½’ï¼Œå³ Sigmoid å‡½æ•°æ‹Ÿåˆï¼ŒäºŒåˆ†ç±»
- `sklearn.naive_bayes` æœ´ç´ è´å¶æ–¯æ¦‚ç‡åˆ†ç±»
  - å…ˆéªŒæ¦‚ç‡ `class_prior_`
  - æ ·æœ¬æ•° `class_count_`
  - å‡å€¼ `theta_`
  - æ–¹å·® `sigma_`
  - è¿”å›é¢„æµ‹æ¦‚ç‡ `predict_proba(x)`
  - è¿”å›å¢é‡è®­ç»ƒ `partial_fit(x, y, classes=[], sample_weight=np.array([]))`
  - `GaussianNB()` é«˜æ–¯æœ´ç´ è´å¶æ–¯
  - `MultinomialNB()` å¤šé¡¹å¼æœ´ç´ è´å¶æ–¯ï¼Œä»¥æ¬¡æ•°ä¸ºç‰¹å¾
  - `BernoulliNB()` ä¼¯åŠªåˆ©æœ´ç´ è´å¶æ–¯ï¼Œä»¥äºŒè¿›åˆ¶æˆ–å¸ƒå°”ä¸ºç‰¹å¾
- `sklearn.neighbors.KNeighborsClassifier()` K è¿‘é‚»è·ç¦»åˆ†ç±»
  - è·ç¦»å’Œä¸‹æ ‡ `kneighbors(x)`
- `sklearn.svm.SVC()` å‘é‡æœºåˆ†ç±»
- `sklearn.tree.DecisionTreeClassifier()` å†³ç­–æ ‘åˆ†ç±»
- `sklearn.cluster.KMeans(n_clusters=3)` K èšç±»
- `sklearn.decomposition`
  - `PCA(n_components=2)` é™ç»´
  - `LatentDirichletAllocation(n_topics=3, max_iter=100, random_state=1)` æ½œåœ¨ä¸»é¢˜åˆ†é…ï¼Œè®­ç»ƒè¯é¢‘çŸ©é˜µ
    - ä¸»é¢˜è¯é¢‘ `topic_word_`
    - å†…å®¹è¯é¢‘çŸ©é˜µ(ä¸»é¢˜æ•° x å…³é”®è¯æ•°) `components_`
    - å›°æƒ‘åº¦ `perplexity(x)`
- `sklearn.feature_extraction.text` ç‰¹å¾æå–æ–‡å­—ï¼Œè®­ç»ƒåˆ†è¯è½¬æ¢ä¸ºè¯é¢‘çŸ©é˜µ
  - ç‰¹å¾è¯è¡¨ `get_feature_names()`
  - `CountVectorizer()` è®¡æ•°å‘é‡åŒ–ï¼Œç»Ÿè®¡ç‰¹å¾è¯ä¸ªæ•°
  - `TfidfVectorizer(strip_accents='unicode', max_features=100, stop_words=[], max_df=.99, min_df=.01)` TF-IDF å‘é‡åŒ–ï¼Œç»Ÿè®¡ç‰¹å¾è¯æ¦‚ç‡
  - `TfidfTransformer()` TF-IDE å€¼ï¼Œè®­ç»ƒè®¡æ•°è¯é¢‘è½¬æ¢ä¸ºæ¦‚ç‡è¯é¢‘
- `sklearn.model_selection(estimator=lr, cv=4, random_state=1, train_size=.8)` æ¨¡å‹é€‰æ‹©
  - æœ€ä½³æ¨¡å‹ `best_estimator_`
  - æœ€ä½³å‚æ•° `best_params_`
  - æœ€ä½³è¯„åˆ† `best_score_`
  - è®­ç»ƒè®°å½• `cv_results_`
  - è®­ç»ƒ `fit(x, y)`
  - `GridSearchCV(param_grid={weights:[]})` ç½‘æ ¼æœç´¢
  - `RandomizedSearchCV(param_distributions={weights:[]}, n_iter=3)` éšæœºæœç´¢
  - `learning_curve()` å­¦ä¹ æ›²çº¿ï¼Œæ£€æŸ¥æ‹Ÿåˆæƒ…å†µ
  - `validation_curve()` éªŒè¯æ›²çº¿ï¼Œæ£€æŸ¥æ¨¡å‹æƒ…å†µ
  - `train_test_split(x, y)` éšæœºåˆ’åˆ†ï¼Œè¿”å› x è®­ç»ƒ x æµ‹è¯• y è®­ç»ƒ y æµ‹è¯• 4 ä¸ªæ•°ç»„
  - `StratifiedShuffleSplit(n_splits=3)` åˆ†å±‚æ´—ç‰Œåˆ’åˆ†
    - åˆ’åˆ†ä¸‹æ ‡ `split(x, y)`
- `sklearn.pipeline.Pipeline([('sc',StandardScaler()), ('pca',PCA(n_components=2)), ('clf',LogisticRegression())])` ç®¡çº¿
- `sklearn.preprocessing`
  - `StandardScaler()` æ ‡å‡†åŒ–ï¼Œç¼©æ”¾åˆ°æ ‡å‡†æ­£æ€åˆ†å¸ƒ
  - `Normalizer()` å½’ä¸€åŒ–ï¼Œç¼©æ”¾åˆ° 01 åŒºé—´
  - `Binarizer(threshold=2)` äºŒå€¼åŒ–
  - `LabelBinarizer()` æ ‡ç­¾äºŒè¿›åˆ¶ç¼–ç ï¼Œæ–‡å­—äºŒè¿›åˆ¶åŒ–
  - `LabelEncoder()` æ ‡ç­¾ç¼–ç ï¼Œæ–‡å­—æ•°å€¼åŒ–
  - `OneHotEncoder(sparse=False)` ç‹¬çƒ­ç¼–ç ï¼Œæ•°å€¼äºŒè¿›åˆ¶åŒ–
  - `Imputer(missing_values='NaN', strategy='mean')` ç¼ºå¤±å€¼
  - `PolynomialFeatures(degree=2)` å¤šé¡¹å¼è®¡ç®—
- `sklearn.cross_validation.cross_val_score(x, y, lr, cv=4)` äº¤å‰éªŒè¯
- `sklearn.metrics(y_test, y_pred)`
  - `mean_absolute_error()` æ–¹å·®ï¼Œæµ‹å›å½’
  - `mean_squared_error()` æ ‡å‡†å·®ï¼Œæµ‹å›å½’
  - `r2_score()` R è¯„åˆ†ï¼Œæµ‹å›å½’ï¼Œè¶‹äº 1 å¥½è¶‹äº 0 å·®
  - `accuracy_score()` å‡†ç¡®ç‡ï¼Œæµ‹åˆ†ç±»
  - `classification_report()` åˆ†ç±»ç»Ÿè®¡ï¼Œæµ‹åˆ†ç±»
  - `confusion_matrix()` æ··æ·†çŸ©é˜µï¼Œæµ‹åˆ†ç±»
  - `adjusted_rand_score()` è°ƒæ•´ç³»æ•°ï¼Œæµ‹èšç±»ï¼Œè¶‹äº 1 å¥½è¶‹äº-1 å·®
  - `homogeneity_score()` åŒè´¨æ€§ï¼Œæµ‹èšç±»ï¼Œå•æ ·æœ¬ç¾¤é›†æ¦‚ç‡ï¼Œç›¸åå®Œæ•´æ€§å•ç¾¤é›†æ¦‚ç‡
  - `v_measure_score()` V è¯„åˆ†ï¼Œæµ‹èšç±»ï¼ŒåŒè´¨æ€§ä¸å®Œæ•´æ€§çš„å‡å€¼

# åˆ†è¯ jieba

- é»˜è®¤
- è¯æ€§è¿‡æ»¤
- è‡ªå®šä¹‰è¯å…¸

```py
import jieba

# ä¸€èˆ¬è¿‡æ»¤
def chinese_cut1(text):
    return ' '.join(jieba.cut(text, cut_all = False)) # ç²¾ç¡®æ¨¡å¼

datacutted = data.apply(chinese_cut1)
```

## è¯æ€§è¿‡æ»¤

```py
import jieba.posseg

# è¯æ€§è¿‡æ»¤
def chinese_cut2(text):
    result = jieba.posseg.cut(text)
    return ' '.join(x.word for x in result if x.flag == 'a' or x.flag == 'n' or x.flag == 'v')

datacutted = data.apply(chinese_cut2)
```

## è‡ªå®šä¹‰è¯å…¸

- è¯å…¸ï¼šUTF-8 ç¼–ç ï¼Œä¸€è¯ä¸€æ¡ï¼Œç©ºæ ¼é—´éš”ï¼Œæ¯æ¡ 3 ä¸ªç‰¹å¾ï¼Œword ä¸ºè¯(å¿…é¡»)ï¼Œfreq ä¸ºè¯é¢‘ï¼Œword_type ä¸ºè¯æ€§

```py
jieba.load_userdict('dict.txt') # è‡ªå®šä¹‰è¯å…¸

# åŠ¨æ€ä¿®æ”¹è¯å…¸
jieba.add_word('newword', freq = 10, tag = 'nz') # æ·»åŠ è‡ªå®šä¹‰è¯
jieba.del_word('word') # åˆ é™¤è‡ªå®šä¹‰è¯

jieba.suggest_freq(line.strip(), True) for line in open('dict.txt', 'r', encoding = 'utf8') # æ‰¹é‡ä¿®æ”¹è¯é¢‘
```

# å¤šçº¿ç¨‹ trio

```py
import trio
import numpy as np

async def main():
    async with trio.open_nursery() as nursery:
        send_channel, receive_channel = trio.open_memory_channel(0) # åˆ›å»ºé€šé“ï¼Œä¼ å…¥é€šé“å¯¹è±¡
        nursery.start_soon(thread1, send_channel)
        nursery.start_soon(thread2, receive_channel)

async def thread1(send_channel):
    print("çº¿ç¨‹1ï¼Œå…¬å¸è€æ¿")
    async with send_channel:
        for i in range(10):
            await trio.sleep(1.) # ä¼‘æ¯
            cmd = np.random.randint(10)
            print("è€æ¿å‘å‡ºæŒ‡ç¤ºï¼š{!r}".format(cmd)) # ç»™ç§˜ä¹¦å‘æŒ‡ç¤º
            await send_channel.send(cmd)

async def thread2(receive_channel):
    print("çº¿ç¨‹2ï¼Œç§˜ä¹¦")
    async with receive_channel:
        async for value in receive_channel: # ç­‰å¾…è€æ¿æŒ‡ç¤º
            print("ç§˜ä¹¦æ”¶åˆ°æŒ‡ç¤ºï¼š{!r}".format(value))

trio.run(main)
```
