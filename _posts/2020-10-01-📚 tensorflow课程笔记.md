---
layout: post
title: ğŸ“š tensorflowè¯¾ç¨‹ç¬”è®°
img: header_post.jpg
tags: [tensorflow, ğŸ“š]
---

- [åŸºç¡€](#åŸºç¡€)
- [é¢„å¤„ç†](#é¢„å¤„ç†)
- [å‡æ–¹è¯¯å·®å‡½æ•° MSE](#å‡æ–¹è¯¯å·®å‡½æ•°-mse)
- [å…¨è¿æ¥å±‚ Dense](#å…¨è¿æ¥å±‚-dense)
- [å‡ç»´ é™ç»´](#å‡ç»´-é™ç»´)
- [æ•°ç»„åˆå¹¶](#æ•°ç»„åˆå¹¶)
- [çŸ©é˜µè½¬ç½® transpose](#çŸ©é˜µè½¬ç½®-transpose)
- [èŒƒæ•° tf.norm](#èŒƒæ•°-tfnorm)
- [æœ€å¤§ æœ€å° å¹³å‡](#æœ€å¤§-æœ€å°-å¹³å‡)
- [å¼ é‡æ’åº](#å¼ é‡æ’åº)

# åŸºç¡€

```bash
$ pip install tensorflow
$ pip install matplotlib seaborn
$ pip install Pillow opencv-python opencv-contrib-python
$ pip install scikit-learn
# $ pip install numpy pandas # å·²åŒ…å«
$ sudo apt install python3-tk # linux only
```

```py
import numpy as np
import tensorflow as tf
from tensorflow.keras.layers import Flatten, Dense

def run():
    ds = tf.keras.datasets.mnist
    (train_x, train_y), (test_x, test_y) = ds.load_data()
    print("train_x.shape:", train_x.shape, ", train_y.shape:", train_y.shape)
    print("test_x.shape:", test_x.shape, ", test_y.shape:", test_y.shape)
    # æ­£è¦åŒ–
    train_x = tf.keras.utils.normalize(train_x)
    test_x = tf.keras.utils.normalize(test_x)
    # one-hot
    train_y = tf.keras.utils.to_categorical(train_y)
    test_y = tf.keras.utils.to_categorical(test_y)
    print("train_y.shape:", train_y.shape, ", test_y.shape:", test_y.shape)
    model = tf.keras.Sequential()
    # æ¨¡å‹å®šä¹‰ï¼ˆç„å­¦ï¼‰
    model.add(Flatten(input_shape=[28, 28]))
    model.add(Dense(1000, activation="relu"))
    model.add(Dense(10, activation="softmax"))
    # æ¨¡å‹æ¦‚è¦
    model.summary()
    # ç¼–è¯‘æ¨¡å‹
    model.compile(
        loss=tf.keras.losses.categorical_crossentropy,
        optimizer=tf.keras.optimizers.Adam(learning_rate=0.001),
        metrics=["accuracy"]
    )
    # è®­ç»ƒæ¨¡å‹å‚æ•°
    history = model.fit(train_x, train_y, validation_data=(
        test_x, test_y), epochs=1, batch_size=128)
    score = model.evaluate(test_x, test_y, batch_size=128)
    print("è®­ç»ƒè¯„ä»·åˆ†æ•°:", score)
    result = model.predict(test_x, batch_size=128)
    print("åŸå§‹å€¼:", np.argmax(test_y[:20], axis=1))
    print("é¢„æµ‹å€¼:", np.argmax(result[:20], axis=1))

run()
```

# é¢„å¤„ç†

```py
from tensorflow.keras.preprocessing.sequence import pad_sequences
comment1 = [1, 2, 3, 4]
comment2 = [1, 2, 3, 4, 5, 6, 7]
comment3 = [1, 2, 3, 4, 5, 6, 7, 8, 9, 10]
x_train = np.array([comment1, comment2, comment3], dtype=object)
x_test = pad_sequences(x_train) # å·¦è¡¥ 0ï¼Œç»Ÿä¸€æ•°ç»„é•¿åº¦
x_test = pad_sequences(x_train, value=255) # å·¦è¡¥ 255ï¼Œç»Ÿä¸€æ•°ç»„é•¿åº¦
x_test = pad_sequences(x_train, padding="post") # å³è¡¥ 0ï¼Œç»Ÿä¸€æ•°ç»„é•¿åº¦
x_test = pad_sequences(x_train, maxlen=3) # åˆ‡å–æ•°ç»„é•¿åº¦ï¼Œåªä¿ç•™å 3 ä½
x_test = pad_sequences(x_train, maxlen=3, truncating="post") # åˆ‡å–æ•°ç»„é•¿åº¦ï¼Œåªä¿ç•™å‰ 3 ä½
```

# å‡æ–¹è¯¯å·®å‡½æ•° MSE

```py
rows = 1
out = tf.random.uniform([rows, 10])
print("out:", out)
print("é¢„æµ‹å€¼:", tf.math.argmax(out, axis=1), "\n")
y = tf.range(rows)
print("y:", y, "\n")
y = tf.one_hot(y, depth=10)
print("y_one_hot:", y, "\n")
loss = tf.keras.losses.mse(y, out)
print("row loss:", loss, "\n")
loss = tf.reduce_mean(loss)
print("æ€»ä½“æŸå¤±:", loss, "\n")
```

# å…¨è¿æ¥å±‚ Dense

```py
# Dense: y = wx + b
rows = 1
net = tf.keras.layers.Dense(1) # 1 ä¸ªéšè—å±‚ï¼Œ1 ä¸ªç¥ç»å…ƒ
net.build((rows, 1)) # æ¯ä¸ªè®­ç»ƒæ•°æ®æœ‰ 1 ä¸ªç‰¹å¾
print("net.w:", net.kernel) # å‚æ•°ä¸ªæ•°
print("net.b:", net.bias) # å’Œ Dense æ•°ä¸€æ ·
```

# å‡ç»´ é™ç»´

```py
a = tf.range([24])
a = tf.reshape(a, [4, 6])
print(a.shape)
print(a.ndim)
# å¢åŠ ä¸€ä¸ªç»´åº¦ï¼Œç›¸å½“äº [1,2,3]->[[1,2,3]]
b = tf.expand_dims(a, axis=0)
print(b.shape)
print(b.ndim)
# å‡å°‘ç»´åº¦ï¼Œç›¸å½“äº [[1,2,3]]->[1,2,3]
c = tf.squeeze(b, axis=0)
print(c.shape)
print(c.ndim)
```

# æ•°ç»„åˆå¹¶

```py
a = tf.zeros([2, 4, 3])
b = tf.ones([2, 4, 3])
# tf.concat 0 è½´åˆå¹¶ï¼Œ4,4,3
c = tf.concat([a, b], axis=0)
# tf.concat 1 è½´åˆå¹¶ï¼Œ2,8,3
c = tf.concat([a, b], axis=1)
# tf.concat 2 è½´åˆå¹¶ï¼Œ2,4,6
c = tf.concat([a, b], axis=2)
# tf.stack æ‰©å……ä¸€ç»´ï¼Œä¾‹å¦‚æŠŠå¤šä¸ªå›¾ç‰‡æ”¾å…¥ä¸€ä¸ªå¤§æ•°ç»„ä¸­ -> 2,2,4,3
c = tf.stack([a, b], axis=0)
# tf.unstack é™ä½ç»´æ•°ï¼Œæ‹†åˆ†æ•°ç»„
m, n = tf.unstack(c, axis=0)
# tf.broadcast_to æ•°ç»„å¹¿æ’­
a = tf.constant([1, 2, 3])
x = 1
print(a + x)
b = tf.broadcast_to(a, [3, 3])
x = 10
print(b * x)
```

# çŸ©é˜µè½¬ç½® transpose

```py
a = tf.range([12])
a = tf.reshape(a, [4, 3])
print(a)
b = tf.transpose(a) # è¡Œåˆ—äº¤æ¢
print(b)
# 1 å¼  4x4 åƒç´ çš„å½©è‰²å›¾ç‰‡
a = tf.random.uniform([4, 4, 3], minval=0, maxval=10, dtype=tf.int32)
print(a)
# æŒ‡å®šå˜æ¢çš„è½´ç´¢å¼•
b = tf.transpose(a, perm=[0, 2, 1])
print(b)
# æŠŠåˆšæ‰çš„ b å†å˜æ¢å›æ¥
c = tf.transpose(b, perm=[0, 2, 1])
print(c)
```

# èŒƒæ•° tf.norm

```py
# 2 èŒƒæ•°ï¼šå¹³æ–¹å’Œå¼€æ ¹å·
a = tf.fill([1, 2], value=2.)
log("a:", a)
b = tf.norm(a) # è®¡ç®— a çš„èŒƒæ•°
log("açš„2èŒƒæ•°b:", b)
# è®¡ç®—éªŒè¯
a = tf.square(a)
log("açš„å¹³æ–¹:", a)
a = tf.reduce_sum(a)
log("aå¹³æ–¹åçš„å’Œ:", a)
b = tf.sqrt(a)
log("aå¹³æ–¹å’Œåå¼€æ ¹å·:", b)

# 1 èŒƒæ•°ï¼šæ‰€æœ‰å€¼çš„ç»å¯¹å€¼ä¹‹å’Œ
a = tf.range(12, dtype=tf.float32)
a = tf.reshape(a, (4, 3))
a = a - 5
log("a:", a)
b = tf.norm(a, ord=1)
log("açš„1èŒƒæ•°b:", b)
print(tf.reduce_sum(tf.abs(a)))
b = tf.norm(a, ord=1, axis=0)
log("açš„axis=0çš„1èŒƒæ•°b:", b)
```

# æœ€å¤§ æœ€å° å¹³å‡

```py
a = tf.range(12, dtype=tf.float32)
a = tf.reshape(a, (4, 3))
log("aæ•°ç»„:", a)

b = tf.reduce_min(a)
log("aæ•°ç»„æœ€å°å€¼:", b)
b = tf.reduce_max(a)
log("aæ•°ç»„æœ€å¤§å€¼:", b)
b = tf.reduce_mean(a)
log("aæ•°ç»„å¹³å‡å€¼:", b)

b = tf.reduce_min(a, axis=0)
log("aæ•°ç»„axis=0æœ€å°å€¼:", b)
b = tf.reduce_max(a, axis=0)
log("aæ•°ç»„axis=0æœ€å¤§å€¼:", b)
b = tf.reduce_mean(a, axis=0)
log("aæ•°ç»„axis=0å¹³å‡å€¼:", b)

b = tf.argmax(a, axis=1)
log("aæ•°ç»„axis=1çš„æœ€å¤§å€¼ç´¢å¼•ä½ç½®:", b)
b = tf.argmin(a, axis=1)
log("aæ•°ç»„axis=1çš„æœ€å°å€¼ç´¢å¼•ä½ç½®:", b)
```

# å¼ é‡æ’åº

```py
# 1ç»´å¼ é‡æ’åº
a = tf.random.shuffle(tf.range(10))
log("a", a)
# a tf.Tensor([8 2 0 5 7 9 3 1 4 6], shape=(10,), dtype=int32)
# å‡åºæ’åˆ—
b = tf.sort(a, direction="ASCENDING")
log("b", b)
# é™åºæ’åˆ—
b = tf.sort(a, direction="DESCENDING")
log("b", b)
# b tf.Tensor([0 1 2 3 4 5 6 7 8 9], shape=(10,), dtype=int32)
# b tf.Tensor([9 8 7 6 5 4 3 2 1 0], shape=(10,), dtype=int32)
# å‡åºæ’åˆ—ï¼Œè¿”å›ç´¢å¼•ä½ç½®
b = tf.argsort(a, direction="ASCENDING")
log("b", b)
# é™åºæ’åˆ—ï¼Œè¿”å›ç´¢å¼•ä½ç½®
b = tf.argsort(a, direction="DESCENDING")
log("b", b)
# b tf.Tensor([2 7 1 6 8 3 9 4 0 5], shape=(10,), dtype=int32)
# b tf.Tensor([5 0 4 9 3 8 6 1 7 2], shape=(10,), dtype=int32)
# æŒ‰ç´¢å¼•ä½ç½®b, ä»æ•°ç»„aä¸­æ”¶é›†æ•°æ®
c = tf.gather(a, b)
log("c", c)
# c tf.Tensor([9 8 7 6 5 4 3 2 1 0], shape=(10,), dtype=int32)

# 2ç»´å¼ é‡æ’åº
a = tf.random.uniform([3, 5], maxval=10, dtype=tf.int32)
log("a", a)
# a tf.Tensor([[2 5 8 0 4] [1 7 2 4 5] [6 0 2 5 0]], shape=(3, 5), dtype=int32)
# å‡åºæ’åˆ—
b = tf.sort(a, axis=1, direction="ASCENDING")
log("b", b)
# é™åºæ’åˆ—
b = tf.sort(a, axis=1, direction="DESCENDING")
log("b", b)
# b tf.Tensor([[0 2 4 5 8] [1 2 4 5 7] [0 0 2 5 6]], shape=(3, 5), dtype=int32)
# b tf.Tensor([[8 5 4 2 0] [7 5 4 2 1] [6 5 2 0 0]], shape=(3, 5), dtype=int32)
# å‡åºæ’åˆ—ï¼Œè¿”å›ç´¢å¼•ä½ç½®
b = tf.argsort(a, axis=1, direction="ASCENDING")
log("b", b)
# é™åºæ’åˆ—ï¼Œè¿”å›ç´¢å¼•ä½ç½®
b = tf.argsort(a, axis=1, direction="DESCENDING")
log("b", b)
# b tf.Tensor([[3 0 4 1 2] [0 2 3 4 1] [1 4 2 3 0]], shape=(3, 5), dtype=int32)
# b tf.Tensor([[2 1 4 0 3] [1 4 3 2 0] [0 3 2 1 4]], shape=(3, 5), dtype=int32)

# top å€¼
a = tf.random.uniform([3, 5], maxval=10, dtype=tf.int32)
log("a", a)
# a tf.Tensor([[1 2 5 8 7] [6 1 4 3 9] [5 9 6 5 5]], shape=(3, 5), dtype=int32)
# å–æ•°ç»„æ¯è¡Œå‰3ä½
b = tf.math.top_k(a, k=3, sorted=True)
log("b", b.values) # å‰3ä½æ•°å€¼
log("b", b.indices) # å‰3ä½æ•°å€¼ç´¢å¼•
# b tf.Tensor([[8 7 5] [9 6 4] [9 6 5]], shape=(3, 3), dtype=int32)
# b tf.Tensor([[3 4 2] [4 0 2] [1 2 0]], shape=(3, 3), dtype=int32)
```
